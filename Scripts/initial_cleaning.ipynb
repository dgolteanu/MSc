{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from codecs import EncodedFile\n",
    "from copy import deepcopy\n",
    "from chardet import detect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "data_set = \"/Users/dolteanu/local_documents/Coding/Ontario covid data/Ontario_covid/OneDrive_1_2022-02-06/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata\n",
    "metadata = Path(\"/Users/dolteanu/local_documents/Coding/Ontario covid data/Ontario_covid/gisaid_filtered<10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2dict(infile):\n",
    "    \"\"\"\n",
    "    Simple function to read the a csv into a dictionary (faster than pandas)\n",
    "    Args:\n",
    "        infile: Path to input file, comma delimited\n",
    "\n",
    "    Returns:dictionary with first field as key and second as value\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    # will not work if csv file is saved as utf-8 in excel in a MAC, assumes no header\n",
    "    with open(infile, mode='r') as reader:\n",
    "        # data = BytesIO(reader.read())\n",
    "        # data2 = deepcopy(data)\n",
    "        # en = detect(data.read())['encoding']\n",
    "        # reader = EncodedFile(data2, en, file_encoding='ascii')\n",
    "        for line in reader:\n",
    "            if line:\n",
    "                line = line.strip().split(',')\n",
    "                key = line[0]\n",
    "                value = line[1]\n",
    "                dictionary[key] = value\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all fasta files\n",
    "import random\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "\n",
    "# Dictionary to store SeqIO\n",
    "seq_dict = {}\n",
    "# Iterate through all fasta files\n",
    "data_set = Path(data_set).resolve()\n",
    "for file in data_set.glob('[!.]*'):\n",
    "    with open(file) as handle:\n",
    "        seq_dict.update(SeqIO.to_dict(SeqIO.parse(handle, \"fasta\")))\n",
    "print(len(seq_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with Accession ID as keys and cluster name as values\n",
    "# Prints out size of classes (cluster) in metadata \n",
    "# N.B. in MLDSP updated to print class size from seq_dict\n",
    "cluster_dict = {}\n",
    "cluster_dict = csv2dict(metadata)\n",
    "cluster_stats = Counter(cluster_dict.values())\n",
    "print(cluster_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to ensure all samples have a corresponding metadata dict entry \n",
    "# (inverse need not be true, this is useful for re-using the same metadata file after doing deduplication or subsampling)\n",
    "missing_samples = set(seq_dict.keys()).difference(cluster_dict.keys())\n",
    "print(missing_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove filtered samples from fasta that do not have a corresponding metadata label\n",
    "for accession in missing_samples:\n",
    "    seq_dict.pop(accession)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find classes with < X samples per class (useful for min class size)\n",
    "bad_class = []\n",
    "x =10\n",
    "for label, count in cluster_stats.items():\n",
    "    if count < x:\n",
    "        bad_class.append(label)\n",
    "        print(cluster_dict)\n",
    "print(f'Classes with fewer than {x} samples:{bad_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove samples with fewer than X samples per class (eliminate class from fasta)\n",
    "for accession,label in cluster_dict.items():\n",
    "    if label in bad_class and accession in seq_dict.keys():\n",
    "        print(f'Sample removed from fasta:\\n{accession}({label})')\n",
    "        seq_dict.pop(accession)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path & filename to save cleaned fasta\n",
    "SeqIO.write(seq_dict.values(),'cleaned_nextstrain<20.fasta','fasta')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4eda3d9fe943090cb05df5ce8e45003fb8f4723850ba6f9bd2cce3886b69592"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('MLDSP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
