{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notebook used to test & compare outputs between MATLAB & Python implementations\n",
    "## Can run entire notebook at once, some cells expected to be N/A or False for certain methods, see in-line comments, will output txt of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from scipy import fft\n",
    "from scipy.fft import fftshift\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from scipy.stats import pearsonr\n",
    "import Bio\n",
    "from functools import partial\n",
    "\n",
    "import pywt\n",
    "# import os\n",
    "\n",
    "from statistics import median, mean\n",
    "# from one_dimensional_num_mapping import *\n",
    "\n",
    "# plotting\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "# from classification import classify_dismat\n",
    "# from helpers import *\n",
    "# from visualisation import dimReduction\n",
    "# set up\n",
    "# if os.path.exists(\"Sequence_database.idx\"):\n",
    "#     os.remove(\"Sequence_database.idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All validation tests run with Primates datasets from https://doi.org/10.1186/s12864-019-5571-y  \n",
    "\n",
    "data_set = '/Users/dolteanu/local_documents/Coding/MLDSP_dev_git/data/Primates/fastas'\n",
    "metadata = '/Users/dolteanu/local_documents/Coding/MLDSP_dev_git/data/Primates/metadata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function found in preprocessing.py\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "\n",
    "def preprocessing(data_set, max_clust_size, metadata):\n",
    "    \"\"\"Preprocessing of fasta sequences using BioPython into a database of\n",
    "    SeqRecord objects each representing a unique sequence, can handle multiple\n",
    "    sequence fastas.\n",
    "\n",
    "    seqs: main sequence database, dictionary-like object, no info on clusters\n",
    "    cluster_names: list of all cluster names from sub-directory names.\n",
    "\n",
    "    number_of_clusters: integer of the total count of clusters.\n",
    "\n",
    "    cluster_sample_info: Dictionary with keys=cluster_names and values =\n",
    "    a tuple consisting of: (number of samples in cluster,\n",
    "        a list of accession ids corresponding to sequences of that cluster).\n",
    "\n",
    "    total_seq: integer of the total sequence count in dataset.\n",
    "\n",
    "    cluster_dict: depracated with cluster_sample_info, will be removed\n",
    "    \"\"\"\n",
    "    # Dictionary to store SeqIO\n",
    "    seq_dict = {}\n",
    "    # dictionary with Accession ID as keys and cluster name as values\n",
    "    cluster_dict = {}\n",
    "    bad_keys=[]\n",
    "   \n",
    "    # Iterate through all fasta files\n",
    "    for f in sorted(os.listdir(data_set)):\n",
    "        file = os.path.join(data_set, f)\n",
    "        with open(file) as handle:\n",
    "            # SeqIO.index_db() is read only & can't multiprocess, SeqIO.index doesnt take file handle for multi-file, SeqIO_to_dict is all in memory, SeqIO.parse you only get to iterate over data once\n",
    "    #         # single dict\n",
    "            seq_dict.update(SeqIO.to_dict(SeqIO.parse(handle, \"fasta\")))\n",
    "            \n",
    "    cluster_dict = pd.read_csv(metadata,header=None, index_col=0, sep=None, engine='python').squeeze(\"columns\").to_dict()\n",
    "    cluster_stats = Counter(cluster_dict.values())\n",
    "    \n",
    "    # for key in seq_dict.keys():\n",
    "    #     if not key in cluster_dict:\n",
    "    #         bad_keys.append(key)\n",
    "    \n",
    "    # print(bad_keys)\n",
    "    #Might affect order of labels & lead to mislabelling\n",
    "    # for item in bad_keys:\n",
    "    #     seq_dict.pop(item)\n",
    "    \n",
    "    total_seq = len(seq_dict)\n",
    "    return seq_dict, total_seq, cluster_dict, cluster_stats\n",
    "\n",
    "\n",
    "def old_preprocessing(data_set, max_clust_size):\n",
    "    # Dictionary to store SeqIO\n",
    "    seq_dict = {}\n",
    "    cluster_names = sorted(os.listdir(data_set))\n",
    "    # dictionary with Accession ID as keys and cluster name as values\n",
    "    cluster_dict = {}\n",
    "    # number of samples in each cluster\n",
    "    # cluster_samples_info = {}\n",
    "    # count of the number of clusters as int\n",
    "    cluster_stats={}\n",
    "    # Iterate over each cluster (top level directories)\n",
    "    for cluster in cluster_names:\n",
    "        files = os.listdir(os.path.join(data_set, cluster))\n",
    "        files = [os.path.join(data_set, cluster, f) for f in files]\n",
    "        # paths.extend(files)\n",
    "        # get path for cluster as str\n",
    "        cluster_path = os.path.join(data_set, cluster)\n",
    "        # get names of files in cluster as list of str\n",
    "        file_name = sorted(os.listdir(cluster_path))\n",
    "        cluster_stats.update({cluster:len(file_name)})\n",
    "        temp_dict={}\n",
    "        # Iterate over each file in the cluster\n",
    "        for file in file_name:\n",
    "            # get path for each file in cluster as str\n",
    "            file_path = os.path.join(cluster_path, file)\n",
    "            # Required to use SeqIO.index to generate dictionary of SeqRecords (parsed on demand in main script)\n",
    "\n",
    "            # SeqIO.index doesnt take file handle to index multiple seqs to a\n",
    "            # single dict\n",
    "\n",
    "            # Not sure if storing the dict like object of SeqIO.index in a dict forces loading into memory (performance penalty)\n",
    "            seqs = SeqIO.index(file_path, \"fasta\"\n",
    "            #,key_function=get_accession\n",
    "            )\n",
    "            seq_dict.update(seqs)\n",
    "            # Generate second dictionary for cluster info\n",
    "            for accession_id in seqs.keys():\n",
    "                cluster_dict.update({accession_id: cluster})\n",
    "        # if len(temp_dict) >= max_clust_size:\n",
    "        #     subset = dict(random.sample(temp_dict.items(), max_clust_size))\n",
    "        #     print(len(subset))\n",
    "        #     seq_dict.update(subset)\n",
    "        # else:\n",
    "        #     seq_dict.update(temp_dict)\n",
    "        # for accession_id in seq_dict.keys():\n",
    "        #     cluster_dict.update({accession_id: cluster}) \n",
    "    total_seq = len(seq_dict)\n",
    "    del temp_dict \n",
    "    del seqs\n",
    "    return seq_dict, total_seq, cluster_dict, cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions found in one_dimensional_num_mapping.py\n",
    "import numpy as np\n",
    "\n",
    "def num_mapping_AT_CG(sq):\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t == 'A':\n",
    "            numSeq[k] = 1\n",
    "        elif t == 'C':\n",
    "            numSeq[k] = -1\n",
    "        elif t == 'G':\n",
    "            numSeq[k] = -1\n",
    "        elif t == 'T':\n",
    "            numSeq[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_justA(sq):\n",
    "    a = \"A\"\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == a:\n",
    "            numSeq[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_justC(sq):\n",
    "    c = \"C\"\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == c:\n",
    "            numSeq[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_justG(sq):\n",
    "    g = \"G\"\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == g:\n",
    "            numSeq[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_justT(sq):\n",
    "    t_ = \"T\"\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == t_:\n",
    "            numSeq[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_Real(sq):\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == \"A\":\n",
    "            numSeq[k] = -1.5\n",
    "        elif t.upper() == \"C\":\n",
    "            numSeq[k] = 0.5\n",
    "        elif t.upper() == \"G\":\n",
    "            numSeq[k] = -0.5\n",
    "        elif t.upper() == \"T\":\n",
    "            numSeq[k] = 1.5\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_PP(sq):\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == \"A\":\n",
    "            numSeq[k] = -1\n",
    "        elif t.upper() == \"C\":\n",
    "            numSeq[k] = 1\n",
    "        elif t.upper() == \"G\":\n",
    "            numSeq[k] = -1\n",
    "        elif t.upper() == \"T\":\n",
    "            numSeq[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_IntN(sq):\n",
    "    dob = ['T', 'C', 'A', 'G']\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        tp = dob.index(t) + 1\n",
    "        numSeq[k] = tp\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_Int(sq):\n",
    "    dob = ['T', 'C', 'A', 'G']\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        tp = dob.index(t)\n",
    "        numSeq[k] = tp\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_EIIP(sq):\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == \"A\":\n",
    "            numSeq[k] = 0.1260\n",
    "        elif t.upper() == \"C\":\n",
    "            numSeq[k] = 0.1340\n",
    "        elif t.upper() == \"G\":\n",
    "            numSeq[k] = 0.0806\n",
    "        elif t.upper() == \"T\":\n",
    "            numSeq[k] = 0.1335\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_Atomic(sq):\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    for k in range(0, length):\n",
    "        t = sq[k]\n",
    "        if t.upper() == \"A\":\n",
    "            numSeq[k] = 70\n",
    "        elif t.upper() == \"C\":\n",
    "            numSeq[k] = 58\n",
    "        elif t.upper() == \"G\":\n",
    "            numSeq[k] = 78\n",
    "        elif t.upper() == \"T\":\n",
    "            numSeq[k] = 66\n",
    "        else:\n",
    "            pass\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_Codons(sq):\n",
    "    # Authored by Wanxin Li @wxli0\n",
    "    length = len(sq)\n",
    "    numSeq = np.zeros(length)\n",
    "    codons = ['TTT','TTC','TTA','TTG','CTT','CTC','CTA','CTG','TCT','TCC','TCA','TCG','AGT','AGC','TAT','TAC',\n",
    "              'TAA','TAG','TGA','TGT','TGC','TGG','CCT','CCC','CCA','CCG','CAT','CAC','CAA','CAG','CGT','CGC',\n",
    "              'CGA','CGG','AGA','AGG','ATT','ATC','ATA','ATG','ACT','ACC','ACA','ACG','AAT','AAC','AAA','AAG',\n",
    "              'GTT','GTC','GTA','GTG','GCT','GCC','GCA','GCG','GAT','GAC','GAA','GAG','GGT','GGC','GGA','GGG']\n",
    "    # for k in range(0, length):\n",
    "    #     if k < length-1:\n",
    "    #         t = sq[k:k+3]\n",
    "    #     elif k == length-1:\n",
    "    #         t = sq[k:k+2] + sq[0]\n",
    "    #     else:\n",
    "    #         t = sq[k] + sq[0:2]\n",
    "    #     tp = codons.index(t)\n",
    "    #     numSeq[k] = tp\n",
    "    for idx in range(length):\n",
    "        if idx <= (length-3):\n",
    "            t = sq[idx:idx+3]\n",
    "        elif idx == (length-2):\n",
    "            t = sq[idx:idx+2]+sq[0:1]\n",
    "        else:\n",
    "            t = sq[idx]+sq[0:2]\n",
    "        tp = codons.index(t)\n",
    "        numSeq[idx] = tp\n",
    "    return numSeq\n",
    "\n",
    "\n",
    "def num_mapping_Doublet(sq):\n",
    "    # Authored by Wanxin Li @wxli0\n",
    "    \"\"\"computes Doublet representation\n",
    "    Keyword arguments:\n",
    "    sq: sequence\n",
    "    \"\"\"\n",
    "    sq_len = len(sq)\n",
    "    doublet = ['AA', 'AT', 'TA', 'AG', 'TT', 'TG', 'AC',\n",
    "               'TC', 'GA', 'CA', 'GT', 'GG', 'CT', 'GC', 'CG', 'CC']\n",
    "    numSeq = np.zeros(len(sq))\n",
    "    # alpha = 0 # TODO: remove alpha for now, if alpha is added, then Codons also needs to be updated\n",
    "\n",
    "    for idx in range(sq_len):\n",
    "        # if alpha == 0:\n",
    "        if idx < (sq_len-1):\n",
    "            t = sq[idx:idx+2]\n",
    "        else:\n",
    "            t = sq[idx]+sq[0]\n",
    "        tp = doublet.index(t)\n",
    "        numSeq[idx] = tp\n",
    "    return numSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions found in helpers.py\n",
    "import math, sys\n",
    "import numpy as np\n",
    "from statistics import median, mean\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def length_calc(seq_list):\n",
    "    \"\"\"calculates length stats\n",
    "\n",
    "    Keyword arguments:\n",
    "    seq_list: a list of squence\n",
    "    \"\"\"\n",
    "    len_list = map(len, seq_list)\n",
    "    max_len = max(len_list)\n",
    "    min_len = min(len_list)\n",
    "    mean_len = mean(len_list)\n",
    "    med_len = median(len_list)\n",
    "\n",
    "    return max_len, min_len, mean_len, med_len\n",
    "\n",
    "def inter_cluster_dist(clsuter,unique_clusters,distance_matrix, cluster_num):\n",
    "    avg_dist = np.zeros((cluster_num,cluster_num))\n",
    "    c_ind = np.zeros(cluster_num)\n",
    "    for h in range(cluster_num):\n",
    "        c_ind[h] = (clsuter == unique_clusters[h])\n",
    "    \n",
    "    for i in range(cluster_num):\n",
    "        for j in range(i+1, cluster_num):\n",
    "            if i==j:         \n",
    "                continue           \n",
    "            else:\n",
    "                dT = distance_matrix[c_ind[i],c_ind[j]]\n",
    "                avg_dist[i,j] = np.mean(np.transpose(dT), 1)  \n",
    "                avg_dist[j,i] = avg_dist[i,j]\n",
    "    return avg_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function from cgr.py\n",
    "import numpy as np\n",
    "\n",
    "def cgr(chars, order, k):\n",
    "    \"\"\"computes CGR representation in standard format: C top-left, G top-right, A bottom-left, T bottom-right\n",
    "\n",
    "    Keyword arguments:\n",
    "    chars: sequence\n",
    "    order: chars to include in CGR\n",
    "    k: value of k-mer\n",
    "    \"\"\"\n",
    "    # set a numpy array of size 2^k,2^k  # remember that arrays are numbered top to bottom & left to right, unlike coordinate plots which go bottom up and left to right\n",
    "    out = np.zeros((2**k,2**k))\n",
    "    # set starting point of cgr plotting in the middle of cgr (x,y)\n",
    "    x = 2**(k-1) \n",
    "    y = 2**(k-1)\n",
    "\n",
    "    for i in range(len(chars)):\n",
    "        char = chars[i]\n",
    "        # devide x coordiate in half, moving it halfway to the left, this is correct if base is C or A\n",
    "        x = int(x/2)\n",
    "        # check to see if base is actually a G or T\n",
    "        if char == order[2] or char == order[3]:  # if the nucleotide is G or T\n",
    "            # add 2^(k-1) aka half the cgr length to the x value, brining it from 1/4 to 3/4\n",
    "            x += 2**(k-1)\n",
    "        # devide y coordiate in half, moving it halfway to the top, this is correct if base is C or G\n",
    "        y = int(y/2)\n",
    "        if char == order[0] or char == order[3]:  # if the nucleotide is A or T\n",
    "            # add 2^(k-1) aka half the cgr length to the y value, brining it from 1/4 to 3/4\n",
    "            y += 2**(k-1)\n",
    "        # if i+1 is greater than or equal to k (i.e. if the position of the base is greater than k )\n",
    "        if (i+1) >= k:\n",
    "            # add plus 1 to the positions y & x in the cgr array\n",
    "            out[y][x] += 1\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions found in visualisation.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from skbio.stats.ordination import pcoa\n",
    "\n",
    "def dimReduction(data, n_dim, method):\n",
    "    \"\"\"\n",
    "    Function will take in a nxm 2d-array and reduce the dimensions of the data using a specified dimensionality\n",
    "    reduction technique (PCA, MDS, or TSNE).\n",
    "    :param np.array data: input data to be transformed\n",
    "    :param int n_dim: dimensions to reduce to\n",
    "    :param str method: which method to use (either 'pca', 'mds', or 'tsne')\n",
    "    :return np.array transformed: nxn_dim array of tranformed data\n",
    "    \"\"\"\n",
    "    if method == 'pca':\n",
    "        pca = PCA(n_components=n_dim,svd_solver='full')\n",
    "        transformed = pca.fit_transform(data)\n",
    "        return transformed\n",
    "    elif method == 'mds':\n",
    "        mds = pcoa(data, number_of_dimensions=n_dim)\n",
    "        transformed = mds.samples\n",
    "        return transformed\n",
    "    elif method == 'tsne':\n",
    "        tsne = TSNE(n_components=n_dim)\n",
    "        transformed = tsne.fit_transform(data)\n",
    "        return transformed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions from classification.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "def classify_dismat(dismat, alabels, folds, total, saveModels=False):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=23)\n",
    "    model_names = {'LinearDiscriminant':LinearDiscriminantAnalysis() #matlab doesn't specify what solver it uses, orginal code used (shrinkage) gamma=0 \n",
    "                   ,'LinearSVM':SVC(kernel='linear',cache_size=1000,decision_function_shape='ovo'), 'QuadSVM':SVC(kernel='poly', degree=2,cache_size=1000,decision_function_shape='ovo'),\n",
    "                   'KNN':KNeighborsClassifier(n_neighbors=1, leaf_size=50, metric='euclidean', weights='uniform', algorithm='brute')\n",
    "                   }\n",
    "    # use 2 additional classifiers if <= 2000 sequences\n",
    "    # if total <= 2000:\n",
    "    #     model_names['SubspaceDiscriminant'] = SVC(kernel='rbf')\n",
    "    #     model_names['SubspaceKNN'] = None\n",
    "\n",
    "    accuracies = defaultdict(list) # dictionary with key: modelname, value: list containing accuracies\n",
    "    confMatrixDict = defaultdict(list) # dictionary with key: modelname, value: list containing confusion matrix displays\n",
    "    misclassifiedIdx = defaultdict(list) # dictionary with key: modelname, value: list containing indices/sequences of dismat that have been misclassifed\n",
    "\n",
    "    # Loop through each model\n",
    "    for modelName in model_names:\n",
    "        model = model_names.get(modelName)\n",
    "        print(model)\n",
    "        # Create pipeline model\n",
    "        if modelName in ['LinearSVM', 'QuadSVM', 'KNN']:\n",
    "            pipeModel = make_pipeline(StandardScaler(), model)\n",
    "        else:\n",
    "            pipeModel = make_pipeline(model)\n",
    "            \n",
    "        for train_index, test_index in kf.split(dismat, alabels):\n",
    "            X_train = dismat[train_index]\n",
    "            X_test = dismat[test_index]\n",
    "            y_train = [alabels[i] for i in train_index]\n",
    "            y_test = [alabels[i] for i in test_index]\n",
    "\n",
    "            # Fit the pipeline model\n",
    "            pipeModel.fit(X_train, y_train)\n",
    "            prediction = pipeModel.predict(X_test)\n",
    "            # Compute and store accuracy of model\n",
    "            accuracies[modelName].append(accuracy_score(y_test, prediction))\n",
    "            print(accuracy_score(y_test, prediction))\n",
    "            # Generate and store confusion matrix\n",
    "            # cm = confusion_matrix(y_test, prediction, labels=list(np.unique(alabels)), normalize=None)\n",
    "            # confMatrixDict[modelName].append(cm)\n",
    "\n",
    "            # Store indices (of dismat) of misclassified sequences\n",
    "            for i in range(len(prediction)):\n",
    "                # if prediction incorrect, add to list of misclassified indices for the model\n",
    "                if prediction[i] != y_test[i]:\n",
    "                    misclassifiedIdx[modelName].append(test_index[i])\n",
    "\n",
    "    # For each model, Calculate mean of accuracies across 10 folds & Sum all confusion matrices across 10 folds\n",
    "    meanModelAccuracies = {} # key: modelName, value: mean accuracy value for model\n",
    "    aggregatedCMatrix = {} # key: modelName, value: summed Confusion Matrix for model\n",
    "    for modelName in accuracies:\n",
    "        meanModelAccuracies[modelName] = np.mean(accuracies.get(modelName))\n",
    "        aggregatedCMatrix[modelName] = np.sum(confMatrixDict.get(modelName), axis=0)\n",
    "\n",
    "    # Mean accuracy value across all classifiers\n",
    "    avgAccuracy = sum(meanModelAccuracies.values()) / len(meanModelAccuracies)\n",
    "\n",
    "    return avgAccuracy, meanModelAccuracies, aggregatedCMatrix, dict(misclassifiedIdx)\n",
    "\n",
    "# Plots and returns a ConfusionMatrix Display object from a raw array\n",
    "def displayConfusionMatrix(confMatrix, alabels):\n",
    "    # generate cm image and plot\n",
    "    confMatrixDisplayObj = ConfusionMatrixDisplay(confusion_matrix=confMatrix, display_labels=list(np.unique(alabels)))\n",
    "    confMatrixDisplayObj.plot(cmap='Blues', colorbar= False)\n",
    "\n",
    "    # access raw cm array: cm_disp.confusion_matrix\n",
    "    # alternative to display: cm_disp = plot_confusion_matrix(pipeModel, X_test, y_test, normalize=None, cmap='Blues', colorbar= False)\n",
    "\n",
    "    return confMatrixDisplayObj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = 'NoData'\n",
    "seq_to_test = 0\n",
    "min_seq_len = 0\n",
    "max_clust_size = 5000000\n",
    "frags_per_seq = 1\n",
    "\n",
    "methods_list = {0: cgr, 1: num_mapping_PP, 2: num_mapping_Int, 3: num_mapping_IntN, 5: num_mapping_Doublet, 6: num_mapping_Codons, 7: num_mapping_Atomic,\n",
    "                8: num_mapping_EIIP, 9: num_mapping_AT_CG, 10: num_mapping_justA, 11: num_mapping_justC, 12: num_mapping_justG, 13: num_mapping_justT, 14: 'PuPyCGR', 15: '1DPuPyCGR'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cgr_PuPyCGR(seq_index):\n",
    "    # seqs is the sequence database, it is being called by accession number\n",
    "    # (keys) which is being iterated over all seq_index,\n",
    "    # (count of all sequences in uploaded dataset) .seq calls the string\n",
    "    seq = str(seq_dict[keys[seq_index]].seq)\n",
    "    seq_new = seq\n",
    "    if method_num == 14:\n",
    "        seq_new = seq_new.replace('G', 'A')\n",
    "        seq_new = seq_new.replace('C', 'T')\n",
    "    cgr_output = cgr(seq_new, 'ACGT', k_val)  # shape:[2^k, 2^k]\n",
    "    # shape:[2^k, 2^k] # may not be appropriate to take by column\n",
    "    # axis=0 takes fft by column, consistent with MATLAB \n",
    "    fft_output = fft.fft(cgr_output,axis=0)\n",
    "    # order='F' flattens the array in fortran index consistent with MATLAB, shape: [1,2^k*2^k], list makes sorting easy for comparison of distance matrices\n",
    "    abs_fft_output = np.abs(fft_output.flatten(order='F'))\n",
    "    return abs_fft_output, fft_output, cgr_output, seq_new, seq  # flatted into 1d array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_1DPuPyCGR(seq_index):\n",
    "    seq = str(seq_dict[keys[seq_index]].seq)\n",
    "    # creates PuPyCGR\n",
    "    seq_new = seq.replace('G', 'A')\n",
    "    seq_new = seq_new.replace('C', 'T')\n",
    "    cgr_raw = cgr(seq_new, 'ACGT', k_val)\n",
    "    # takes only the last (bottom) row but all columns of cgr to make 1DPuPyCGR\n",
    "    cgr_output = cgr_raw[-1, :]\n",
    "    # shape:[1, 2^k] # may not be appropriate to take by column\n",
    "    fft_output = fft.fft(cgr_output)\n",
    "    abs_fft_output = np.abs(fft_output.flatten(order='F'))\n",
    "    return abs_fft_output, fft_output, cgr_output, seq_new, seq # flatted into 1d array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_dimensional_num_mapping_wrapper(seq_index):\n",
    "    # normalize sequences to median sequence length of cluster\n",
    "    seq = str(seq_dict[keys[seq_index]].seq)\n",
    "    if len(seq) >= med_len:\n",
    "        seq_new = seq[0:round(med_len)]\n",
    "    else:\n",
    "        seq_new=seq\n",
    "    num_seq = method(seq_new)\n",
    "    if len(num_seq) < med_len:\n",
    "        pad_width = int(med_len - len(num_seq))\n",
    "        num_seq = pywt.pad(num_seq, pad_width, 'antisymmetric')[pad_width:]\n",
    "    fft_output = fft.fft(num_seq)\n",
    "    abs_fft_output = np.abs(fft_output.flatten()) #order='F' for testing abs_fft_outputs vs matlab\n",
    "    return abs_fft_output, fft_output, num_seq, seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Deprecated, not currently used, may be required for comparing upgma trees or mds\n",
    "# def compute_pearson_coeffient(x, y):\n",
    "#     r = pearsonr(x, y)[0]\n",
    "#     normalized_r = (1-r)/2\n",
    "#     return normalized_r\n",
    "\n",
    "# def compute_pearson_coeffient_wrapper(i, j, abs_fft_output_list):\n",
    "#     # print(abs_fft_output_list)\n",
    "#     # x = abs_fft_output_list[i]\n",
    "#     # y = abs_fft_output_list[indices[1]]\n",
    "#     # print(x)\n",
    "#     # print(y)\n",
    "#     return compute_pearson_coeffient(abs_fft_output_list[i], abs_fft_output_list[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of validation, iterating over all available methods, \n",
    "from IPython.display import clear_output\n",
    "for f in methods_list:\n",
    "    method_num = f\n",
    "    print(method_num)\n",
    "    method = methods_list[f]\n",
    "    if method_num in range(0,14):\n",
    "        method_name = method.__name__\n",
    "    else:\n",
    "        method_name= method\n",
    "    print(method_name)\n",
    "    file = open(f\"./dump/{method_name}_validation.txt\", \"x\")\n",
    "    # all matlab test .mat files were run at k=4\n",
    "    k_val = 4  # used only for CGR-based representations(if methodNum=1,15,16)\n",
    "    #seq_dict, total_seq, cluster_dict, cluster_stats = old_preprocessing(data_set,max_clust_size) #uncomment if using nested folder structure data\n",
    "    # comment line below if using nested folder data instead of metadata.csv\n",
    "    seq_dict, total_seq, cluster_dict, cluster_stats = preprocessing(data_set,max_clust_size, metadata)\n",
    "    keys = list(seq_dict.keys())\n",
    "    values = list(cluster_dict.values())\n",
    "    # Could be parallelized in the future\n",
    "    seqs_length = [len(seq_dict[keys[i]].seq) for i in range(total_seq)]\n",
    "    med_len = median(seqs_length)\n",
    "    labels = [cluster_dict[x] for x in seq_dict.keys()]\n",
    "    fft_output_list = []\n",
    "    abs_fft_output_list = []\n",
    "    cgr_output_list = []\n",
    "    seq_new_list = []\n",
    "    seq_list=[]\n",
    "    print('Generating numerical sequences, applying DFT, computing magnitude spectra .... \\n')\n",
    "    for seq_index in range(total_seq):\n",
    "        if method_num == 0 or method_num == 14:\n",
    "            abs_fft_output, fft_output, cgr_output, seq_new, seq = compute_cgr_PuPyCGR(seq_index)\n",
    "            abs_fft_output_list.append(abs_fft_output)\n",
    "            fft_output_list.append(fft_output)\n",
    "            cgr_output_list.append(cgr_output)\n",
    "            seq_new_list.append(seq_new)\n",
    "            seq_list.append(seq)\n",
    "            \n",
    "        elif method_num == 15:\n",
    "            abs_fft_output, fft_output, cgr_output, seq_new, seq = compute_1DPuPyCGR(seq_index)\n",
    "            abs_fft_output_list.append(abs_fft_output)\n",
    "            fft_output_list.append(fft_output)\n",
    "            cgr_output_list.append(cgr_output)\n",
    "            seq_new_list.append(seq_new)\n",
    "            seq_list.append(seq)\n",
    "\n",
    "        else:\n",
    "            abs_fft_output, fft_output, seq_new, seq = one_dimensional_num_mapping_wrapper(seq_index)\n",
    "            fft_output_list.append(fft_output)\n",
    "            abs_fft_output_list.append(abs_fft_output)\n",
    "            seq_new_list.append(seq_new)\n",
    "            seq_list.append(seq)\n",
    "    \n",
    "    print('Building distance matrix')\n",
    "    distance_matrix = (1-np.corrcoef(abs_fft_output_list))/2\n",
    "\n",
    "\n",
    "    print('Performing classification .... \\n')\n",
    "    folds = 10\n",
    "    if (total_seq < folds):\n",
    "        folds = total_seq\n",
    "    mean_accuracy, accuracies, confusion_matrix, misclassified_id = classify_dismat(distance_matrix, labels, folds, total_seq)\n",
    "    print('Classification accuracy 5 classifiers:\\n', accuracies, file=file)\n",
    "    print('**** Processing completed ****\\n')\n",
    "\n",
    "\n",
    "    ### VALIDATION START ###\n",
    "    from scipy.io import loadmat\n",
    "    #load .mat file from your machine\n",
    "    \n",
    "    matlab = loadmat(f'./MATLAB data/Primates_testing_all_numerical_methods/primates_{method_name}.mat',simplify_cells=True)\n",
    "    locals().update(matlab)\n",
    "    # compare raw input sequences\n",
    "    print(f\"\\nComparing raw input sequences:\\n{seq_list==Seq}\", file=file)\n",
    "\n",
    "    # compare output sequences for cgr methods; \n",
    "    if method_num in [0,14,15]:\n",
    "        print(f\"\\nCompare cgr inputs, only different from raw input sequences for non-standard cgr i.e Purine-Pyrimidine & 1D CGR:\\n {seq_new_list==sequence}\", file=file)\n",
    "        print(\"\\nComparing each sample's cgr output\", file=file)\n",
    "        for thing in range(total_seq):\n",
    "            print(True==np.allclose(cgr_output_list[thing],nmValSH[thing]),file=file)\n",
    "    else:\n",
    "        print(\"\\nCompare output of numerical representation:\",file=file)\n",
    "        for thing in range(total_seq):\n",
    "            print(seq_new_list[thing]==nmValSH[thing],file=file)\n",
    "    \n",
    "    print(\"\\nCompare fft outputs:\",file=file)\n",
    "    for thing in range(total_seq):\n",
    "        print(np.allclose(fft_output_list[thing],f[thing]),file=file)\n",
    "    \n",
    "    print(\"\\nCompare magnitudes of ffts:\",file=file)\n",
    "    for thing in range(total_seq):\n",
    "        print(np.allclose(abs_fft_output_list[thing],lg[thing]),file=file)\n",
    "    \n",
    "    print(f\"\\nCompare distance matrix:\\n{np.allclose(distance_matrix,disMat,atol=1e-15,rtol=1e-11)}\",file=file)\n",
    "    file.close()\n",
    "    clear_output()\n",
    "    # objects = dir()\n",
    "    # for obj in objects:\n",
    "    #     if not obj.startswith(\"__\"):\n",
    "    #         del globals()[obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolteanu/.pyenv/versions/MLDSP/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "seq_dict, total_seq, cluster_dict, cluster_stats = preprocessing(data_set,max_clust_size, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_num = 0\n",
    "k_val = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable holding all the keys (accession numbers) for corresponding clusters\n",
    "\n",
    "keys = list(seq_dict.keys())\n",
    "\n",
    "values = list(cluster_dict.values())\n",
    "# Could be parallelized in the future\n",
    "\n",
    "seqs_length = [len(seq_dict[keys[i]].seq) for i in range(total_seq)]\n",
    "med_len = median(seqs_length)\n",
    "labels = [cluster_dict[x] for x in seq_dict.keys()]\n",
    "fft_output_list = []\n",
    "abs_fft_output_list = []\n",
    "cgr_output_list = []\n",
    "seq_new_list = []\n",
    "seq_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Phylogenetic trees not compared\n",
    "# def phylogenetic_tree(distance_matrix):\n",
    "#     names = keys\n",
    "#     matrix = triangle_matrix\n",
    "#     distance_matrix = DistanceMatrix(names, matrix)\n",
    "#     constructor = DistanceTreeConstructor()\n",
    "#     nj_tree = constructor.nj(distance_matrix)\n",
    "#     # newick may not be need to be quoted\n",
    "#     neighbour_joining_tree = nj_tree.format('newick')\n",
    "#     upgma = constructor.upgma(distance_matrix)\n",
    "#     upgma_tree = upgma.format('newick')\n",
    "#     print(upgma_tree, file=tree_print)\n",
    "#     # can add code here for visualization with matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating numerical sequences, applying DFT, computing magnitude spectra .... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Generating numerical sequences, applying DFT, computing magnitude spectra .... \\n')\n",
    "for seq_index in range(total_seq):\n",
    "    if method_num == 0 or method_num == 14:\n",
    "        abs_fft_output, fft_output, cgr_output, seq_new, seq = compute_cgr_PuPyCGR(seq_index)\n",
    "        abs_fft_output_list.append(abs_fft_output)\n",
    "        fft_output_list.append(fft_output)\n",
    "        cgr_output_list.append(cgr_output)\n",
    "        seq_new_list.append(seq_new)\n",
    "        seq_list.append(seq)\n",
    "        \n",
    "    elif method_num == 15:\n",
    "        abs_fft_output, fft_output, cgr_output, seq_new, seq = compute_1DPuPyCGR(seq_index)\n",
    "        abs_fft_output_list.append(abs_fft_output)\n",
    "        fft_output_list.append(fft_output)\n",
    "        cgr_output_list.append(cgr_output)\n",
    "        seq_new_list.append(seq_new)\n",
    "        seq_list.append(seq)\n",
    "\n",
    "    else:\n",
    "        abs_fft_output, fft_output, seq_new, seq = one_dimensional_num_mapping_wrapper(seq_index)\n",
    "        fft_output_list.append(fft_output)\n",
    "        abs_fft_output_list.append(abs_fft_output)\n",
    "        seq_new_list.append(seq_new)\n",
    "        seq_list.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building distance matrix\n"
     ]
    }
   ],
   "source": [
    "print('Building distance matrix')\n",
    "# distance_matrix = []\n",
    "# for i in range(total_seq):\n",
    "#     for j in range(total_seq):\n",
    "#         distance_matrix.append(compute_pearson_coeffient_wrapper(i,j,abs_fft_output_list)) \n",
    "# distance_matrix = np.array(distance_matrix).reshape(total_seq, total_seq)\n",
    "# np.savetxt('distmat.txt', distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dist_mat = (1-np.corrcoef(abs_fft_output_list))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(distance_matrix,new_dist_mat,atol=1e-15,rtol=1e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # print('Building Phylogenetic Trees')\n",
    "    # matrix_list = distance_matrix.tolist()\n",
    "    # triangle_matrix = []\n",
    "    # # loop to create triangle matrix as nested list\n",
    "    # for i in range(total_seq):\n",
    "    #     row = []\n",
    "    #     row = (matrix_list[i][0:i+1])\n",
    "    #     triangle_matrix.append(row)\n",
    "    # # change filename to unique ID\n",
    "    # tree_print = open('upgma.tree', 'a')\n",
    "    # phylogenetic_tree(triangle_matrix)\n",
    "    # tree_print.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing classification .... \n",
      "\n",
      "LinearDiscriminantAnalysis()\n",
      "0.9333333333333333\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "0.8\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.9285714285714286\n",
      "13\n",
      "1.0\n",
      "13\n",
      "SVC(kernel='linear')\n",
      "1.0\n",
      "14\n",
      "1.0\n",
      "14\n",
      "1.0\n",
      "14\n",
      "1.0\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "1.0\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "0.9285714285714286\n",
      "13\n",
      "0.9285714285714286\n",
      "13\n",
      "SVC(degree=2, kernel='poly')\n",
      "0.8666666666666667\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.6\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.7333333333333333\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.9333333333333333\n",
      "14\n",
      "0.8571428571428571\n",
      "13\n",
      "0.9285714285714286\n",
      "13\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, metric='euclidean',\n",
      "                     n_neighbors=1)\n",
      "1.0\n",
      "14\n",
      "1.0\n",
      "14\n",
      "1.0\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "1.0\n",
      "14\n",
      "0.8\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.8666666666666667\n",
      "14\n",
      "0.8571428571428571\n",
      "13\n",
      "1.0\n",
      "13\n",
      "Classification accuracy 5 classifiers\n",
      " {'LinearDiscriminant': 0.9061904761904762, 'LinearSVM': 0.9657142857142856, 'QuadSVM': 0.8385714285714286, 'KNN': 0.9257142857142858}\n",
      "**** Processing completed ****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Performing classification .... \\n')\n",
    "folds = 10\n",
    "if (total_seq < folds):\n",
    "    folds = total_seq\n",
    "mean_accuracy, accuracies, confusion_matrix, misclassified_id = classify_dismat(new_dist_mat, labels, folds, total_seq)\n",
    "# accuracy,avg_accuracy, clNames, cMat\n",
    "# accuracies = [accuracy, avg_accuracy];\n",
    "print('Classification accuracy 5 classifiers\\n', accuracies)\n",
    "print('**** Processing completed ****\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dolteanu/.pyenv/versions/MLDSP/lib/python3.8/site-packages/scipy/io/matlab/mio.py:226: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    }
   ],
   "source": [
    "# Save entire matlab workspace as .mat \n",
    "# Use matlab mldsp version from github as variables have been added for testing; make sure k_val (where applicable) and methods match\n",
    "from scipy.io import loadmat\n",
    "#load .mat file from your machine\n",
    "matlab = loadmat('/Users/dolteanu/local_documents/Coding/MLDSP_dev_git/Validation/primates_cgr.mat',simplify_cells=True)\n",
    "locals().update(matlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing convention in this notebook: python variable on the left, matlab variable on the right\n",
    "# compare accession number\n",
    "keys==AcNmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare raw input sequences\n",
    "seq_list==Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run only for cgr based methods\n",
    "# compare output sequences for cgr methods; regular cgr will be the same as previous cell since raw sequence is used for cgr generation\n",
    "seq_new_list==sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only for 1D numerical representation methods\n",
    "# Compare output of numerical representation\n",
    "for thing in range(total_seq):\n",
    "    print(seq_new_list[thing]==nmValSH[thing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run only for cgr methods\n",
    "# compare CGRs\n",
    "for thing in range(total_seq):\n",
    "    print(True==np.allclose(cgr_output_list[thing],nmValSH[thing]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fft outputs\n",
    "for thing in range(total_seq):\n",
    "    print(np.allclose(fft_output_list[thing],f[thing]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compare magnitudes of ffts\n",
    "for thing in range(total_seq):\n",
    "    print(np.allclose(abs_fft_output_list[thing],lg[thing]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare distance matrices\n",
    "#modify exponent of 'rtol' to find similarity of dist mats, atol should be left untouched as it tests precision of zeros (diagonal)\n",
    "np.allclose(new_dist_mat,disMat,atol=1e-15,rtol=1e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare MDS outputs-currently not matching due to sklearn using SMACOF algorithm while matlab uses SVD.\n",
    "scaled_distance_matrix = dimReduction(new_dist_mat, n_dim=3, method='pca')\n",
    "np.isclose(scaled_distance_matrix,Y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b894f052b0c97d72a3ddc1599b7ff149637223c5b927863dbbab7de929fa3d49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('MLDSP')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
